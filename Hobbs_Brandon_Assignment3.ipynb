{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting....\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,676,842\n",
      "Trainable params: 1,676,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:113: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=25, verbose=1, callbacks=[<keras.ca..., steps_per_epoch=97)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "97/97 [==============================] - 76s 786ms/step - loss: 2.1271 - accuracy: 0.2288\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 77s 790ms/step - loss: 1.9123 - accuracy: 0.3049\n",
      "Epoch 3/25\n",
      "97/97 [==============================] - 78s 806ms/step - loss: 1.7923 - accuracy: 0.3484\n",
      "Epoch 4/25\n",
      "97/97 [==============================] - 75s 771ms/step - loss: 1.7002 - accuracy: 0.3879\n",
      "Epoch 5/25\n",
      "97/97 [==============================] - 125s 1s/step - loss: 1.6296 - accuracy: 0.4138\n",
      "Epoch 6/25\n",
      "97/97 [==============================] - 150s 2s/step - loss: 1.5698 - accuracy: 0.4341\n",
      "Epoch 7/25\n",
      "97/97 [==============================] - 156s 2s/step - loss: 1.5261 - accuracy: 0.4538\n",
      "Epoch 8/25\n",
      "97/97 [==============================] - 155s 2s/step - loss: 1.4845 - accuracy: 0.4685\n",
      "Epoch 9/25\n",
      "97/97 [==============================] - 152s 2s/step - loss: 1.4470 - accuracy: 0.4844\n",
      "Epoch 10/25\n",
      "97/97 [==============================] - 151s 2s/step - loss: 1.4247 - accuracy: 0.4923\n",
      "Epoch 11/25\n",
      "97/97 [==============================] - 150s 2s/step - loss: 1.3882 - accuracy: 0.5033\n",
      "Epoch 12/25\n",
      "97/97 [==============================] - 149s 2s/step - loss: 1.3627 - accuracy: 0.5152\n",
      "Epoch 13/25\n",
      "97/97 [==============================] - 152s 2s/step - loss: 1.3341 - accuracy: 0.5232\n",
      "Epoch 14/25\n",
      "97/97 [==============================] - 149s 2s/step - loss: 1.3181 - accuracy: 0.5314\n",
      "Epoch 15/25\n",
      "97/97 [==============================] - 154s 2s/step - loss: 1.3017 - accuracy: 0.5378\n",
      "Epoch 16/25\n",
      "97/97 [==============================] - 150s 2s/step - loss: 1.2804 - accuracy: 0.5454\n",
      "Epoch 17/25\n",
      "97/97 [==============================] - 150s 2s/step - loss: 1.2630 - accuracy: 0.5521\n",
      "Epoch 18/25\n",
      "97/97 [==============================] - 150s 2s/step - loss: 1.2536 - accuracy: 0.5529\n",
      "Epoch 19/25\n",
      "97/97 [==============================] - 148s 2s/step - loss: 1.2312 - accuracy: 0.5622\n",
      "Epoch 20/25\n",
      "97/97 [==============================] - 154s 2s/step - loss: 1.2198 - accuracy: 0.5695\n",
      "Epoch 21/25\n",
      "97/97 [==============================] - 152s 2s/step - loss: 1.2059 - accuracy: 0.5736\n",
      "Epoch 22/25\n",
      "97/97 [==============================] - 90s 931ms/step - loss: 1.1912 - accuracy: 0.5787\n",
      "Epoch 23/25\n",
      "97/97 [==============================] - 82s 842ms/step - loss: 1.1777 - accuracy: 0.5834\n",
      "Epoch 24/25\n",
      "97/97 [==============================] - 81s 831ms/step - loss: 1.1660 - accuracy: 0.5889\n",
      "Epoch 25/25\n",
      "97/97 [==============================] - 80s 828ms/step - loss: 1.1528 - accuracy: 0.5911\n",
      "10000/10000 [==============================] - 7s 675us/step\n",
      "Test score: 1.0114599853515625\n",
      "Test accuracy: 0.6402999758720398\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils \n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from keras.optimizers import SGD, Adam, RMSprop \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context=ssl._create_unverified_context\n",
    "\n",
    "\n",
    "NUM_TO_AUGMENT=5 \n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3 \n",
    "IMG_ROWS = 32 \n",
    "IMG_COLS = 32 \n",
    "\n",
    "#constant \n",
    "BATCH_SIZE = 512 \n",
    "NB_EPOCH = 25 \n",
    "NB_CLASSES = 10 \n",
    "VERBOSE = 1 \n",
    "VALIDATION_SPLIT = 0.2 \n",
    "OPTIM = RMSprop() \n",
    "\n",
    "#load dataset \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "#augmenting\n",
    "print(\"Augmenting....\")\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "xtas, ytas = [], []\n",
    " \n",
    "for i in range(X_train.shape[0]): \n",
    "    num_aug = 0 \n",
    "    x = X_train[i] # (3, 32, 32) \n",
    "    x = x.reshape((1,) + x.shape) # (1, 3, 32, 32) \n",
    "\n",
    "for x_aug in datagen.flow(x, batch_size=1, save_to_dir ='preview', save_prefix='cifar', save_format='jpeg'): \n",
    "    if num_aug >= NUM_TO_AUGMENT: \n",
    "        break \n",
    "    xtas.append(x_aug[0]) \n",
    "    num_aug += 1\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape) \n",
    "print(X_train.shape[0], 'train samples') \n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES) \n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train /= 255 \n",
    "X_test /= 255\n",
    "\n",
    "# network \n",
    "model = Sequential() \n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Conv2D(32, (3, 3), padding='same')) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25)) \n",
    "model.add(Conv2D(64, (3, 3), padding='same')) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Conv2D(64, 3, 3)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25)) \n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(NB_CLASSES)) \n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#fit the dataget \n",
    "datagen.fit(X_train)\n",
    "\n",
    "# old train \n",
    "#model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy']) \n",
    "#model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, verbose=VERBOSE) \n",
    "#score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE) \n",
    "#print(\"Test score:\", score[0]) \n",
    "#print('Test accuracy:', score[1])\n",
    "\n",
    "#new train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
    "\n",
    "#checkpoints\n",
    "checkpoint_filepath = 'keras_check'\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE), \n",
    "samples_per_epoch=X_train.shape[0], epochs=NB_EPOCH, verbose=VERBOSE, callbacks = [cp_callback]) \n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE) \n",
    "print(\"Test score:\", score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "#save model \n",
    "model_json = model.to_json() \n",
    "open('cifar10_architecture.json', 'w').write(model_json) \n",
    "#And the weights learned by our deep network on the training \n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your face is considered to be PII (Imperva, n.d.). After all, what could possibly be more identifiable to a person than their own face. PII, ethically, and now in many cases legally is to be treated with the highest degree of care. In fact, some places have gone as far as to codify this, e.g., GDPR. If a company starts to scrape images from public sources and then pairs that image with a name then all ideas of privacy have been breached – it would be easy for anyone with access to the data to identify you directly.\n",
    "\n",
    "In Hill (2020) the story of ClearView AI is even worse as those images and names are then turned over to the cops. More than likely the police wouldn’t be able to secure that data without a warrant, but because they are using a 3rd party software they are in the clear. \n",
    "\n",
    "What about real-time facial recognition? Could the police use cameras to search citizens going about their day and then arrest anyone who matches another person with a warrant? Police typically need probable cause to make a stop, is looking similar to a wanted person enough?\n",
    "\n",
    "Moreover, facial recognition isn’t flawless. Najibi (2020) shows that across 5 different systems, females with darker complexion have the lowest accuracy. Darker males are also less accurate than lighter males. These factors could cause more false positives leading to false arrests and detainments.\n",
    "\n",
    "Hill, K. (2020, January 21). The secretive company that might end privacy as we know it. International New York Times, NA. https://link-gale-com.ezproxy.snhu.edu/apps/doc/A611773186/GIC?u=nhc_main&sid=bookmark-GIC&xid=602284b3\n",
    "\n",
    "Imperva. What is personally identifiable information. (n.d.). https://www.imperva.com/ learn/data-security/personally-identifiable-information-pii\n",
    "\n",
    "Najibi, A. (2020). Racial discrimination in face recognition technology. Science in the News. https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
